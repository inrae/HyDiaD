---
title: "Equations for mean and SD_v2"
author: "Betsy"
date: "01/07/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(reader)
```

## *Mean*

*This was the equation used to calculate the weighted mean:* $$\large \overline{\mu} = \frac{\sum_{i}^{N} W_i * X_i}{\sum_{i}^{N} W_i}$$

*where* $i$ *is a combination responder x species for a question*

## *Standard Deviation*

$$\large S = \sqrt{\frac{N}{(N-1)\sum_{i}^{N} W_i} * \sum_{i}^{N} W_i * (X_i - \overline{\mu})^2}  $$ *Where* $W_i$ *is the weighted value for data point* $i$*,* $X_i$ *is the response value for data point* $i$*, and* $\overline{\mu}$ *is the weighted average. Here N is the number of data points that are above zero (i.e. used to calculate the mean). I think this may be a better approach because it takes into account the total number of responses we used in these calculations for each species.*

*The issue we were having involved calculating the correct upper and lower limits for the graph. Previously, I was calculating the mean and SD using the logged data, then exponentiating both answers to calculate the upper and lower limits. This was a mistake, as I needed to calculate the upper and lower limits before exponentiating both the mean and SD. When we use the latter approach, we get a SD that is scaled to the log scale used in the x-axis, so in the figure the variance looks equal on both sides of the mean. Also, the ranges of the SD are now reasonable and not too small or too large given the data.*

*So, here is the corrected code (which is also cleaned up a little better). I indicated which lines the changes were made, and included the code to make all of the figures.*

```{r SurResp, eval = TRUE, echo = TRUE}
###libraries
library(reader)

library(zoo)
library(viridis)
library(scales)
library(tidyverse)

rm(list = ls())

# Species order
SppList <- c("Allis Shad","Twaite Shad",
             "River Lamprey", "Sea Lamprey", 
             "Salmon",  "Sea Trout", 
             "Sturgeon", "Smelt",
             "Eel", "Mullet", "Flounder")

# Survey responses
SurResp <- read_rds("./survey/data_input/DF of survey responses.RDS") #Change path if necessary

#### Step 3: Drop NAs for individual people and species combinations and calculate the response X confidence level column-------
##Note: generally, instances where confidence level = 0 should correspond with response = NA, but this may not always be the case

### First divide questions into 
# those with log scale 
temp3 <- c(3, 4, 6, 7)
# those without log scale 
temp4 <- c(5, 8)

## calculate mutated response * confidence level row-wise:
AllData <- SurResp %>%
  filter(Question %in% c(temp3, temp4)) %>%
  filter(CL > 0) %>%
  drop_na(Response) %>%
  mutate(
    mResponse = case_when(
      Question == 4 ~ 1/Response,
      Question != 4 ~ Response),
    logScale = case_when(
      Question %in% temp3 ~ TRUE,
      Question %in% temp4 ~ FALSE),
    mResponse = case_when(
      Question %in% temp3 ~ log(mResponse),
      Question %in% temp4 ~ mResponse),
    ResConf =  mResponse * CL)

### Now summarize the data for (response * confidence level) and confidence level
### Then calculate weighted mean (mu) and the number of samples with CL > 0 that will be used in the equation as N
SumAllData <- AllData %>%
  group_by(Question, Species) %>%
  summarise(sum_CL = sum(CL),
            sum_CLsquare = sum(CL^2),
            sum_ResConf = sum(ResConf),
            N= n(), 
            Neff = sum_CL^2/sum_CLsquare,
            .groups = 'drop') %>% 
  select(-sum_CLsquare) %>% 
  mutate(mu = sum_ResConf / sum_CL)

SumAllData %>% filter(Species == "Allis Shad")
### to get a dataframe that has the group weighted average associated with each row of data:
AllData <- AllData %>% inner_join(SumAllData, by = c("Question", "Species")) %>% 
  mutate(Species = factor(Species, levels = SppList)) %>% 
  arrange(Species)


# calculate standard deviation and range around mu ( mu +- racine(sd2/N))

Result <- AllData %>% 
      inner_join(SumAllData, by = c("Question", "Species")) %>% 
  group_by(Question, Species, logScale , N, Neff, sum_CL, mu) %>%
  summarise( sum_square = sum(CL*(mResponse - mu)^2), .groups = 'drop') %>% 
  mutate(se = if_else(logScale,
                     sqrt(sum_square / ((Neff-1) * sum_CL)),
                     sqrt(sum_square / ((N-1) * sum_CL))),
         dn =  mu - se,
         up =  mu + se,
         mu_natural = if_else(logScale, exp(mu), mu),
         dn_natural = if_else(logScale, exp(dn), dn),
         up_natural = if_else(logScale, exp(up), up)
         ) %>% 
  mutate(Species = factor(Species, levels = SppList)) %>% 
  arrange(Species)

Result %>% 
  filter(Question == 4) %>% 
  write.csv("./survey/data_output/q4.csv")

question =4
species = "Allis Shad"
responseFigure <- function(question, AllData, Result, species = NULL){
  
  allData <- AllData %>% filter(Question == question)
  result <- Result %>% filter(Question == question)
  if (isNull(species)) {
    allData <-  allData %>% filter(Species %in% species)
    result <-  result %>% filter(Species %in% species)
  }
  
  
  logscale <-  unique(result$logScale)
  
  # label of the graph
  lbls <- setNames(paste(result$Species, "\n sum CL:", result$sum_CL, " N:", result$N,
                         "mu:", round(result$mu, 2), "\U00B1 SD:", round(result$s, 2)), result$Species)
 allData %>% 
  ggplot() +
    geom_point(aes(x = mResponse, y = CL, size = N, fill = N),
               alpha = 0.5, shape = 21, color = "black", stroke = 1.5) +
    facet_wrap(~Species,
               labeller = labeller(lbls)) +
    theme_bw() +
    theme(axis.text = element_text(size = 16), axis.title = element_text(size = 18), 
          title = element_text(size = 18), strip.text.x = element_text(size = 16)) +
    ylim(0, 100) +
    scale_size_continuous(range = c(6, 12), breaks = pretty_breaks(4)) +
    scale_fill_viridis(option = "D", breaks = pretty_breaks(4)) +
    guides(fill = guide_legend(), size = guide_legend()) +
    ylab("Confidence level") +
    xlab("Answer Response") +
       
    
    geom_vline(data = result, aes(xintercept = mu), lty = 2, col = "blue", lwd = 1) +
    geom_rect(data = result, aes(xmin = dn, xmax = up, ymin = 0, ymax = 100), color = "lightblue", alpha = 0.25)
}

    scale_x_log10(breaks = trans_breaks("log10", function(x) 10^x), 
                  labels = trans_format("log10", math_format(10^.x))) +

# Betsy's code too complex
#Calculate summarized part of SD equation for questions WITH logged data:
#i is the question you are using the function on
SDSumLog <- function(i, allData){
  allData %>%
    filter(Question == i) %>%
    group_by(Species) %>%
    mutate(xma = (lResponse - (mu))^2) %>% #Both the Response and the weighted average are on a log scale at this point
    mutate(wxma = xma * CL) %>% #(wi * (xi - u*)^2)
    summarise_at(c("wxma", "CL.x"), sum)
}

#This function calculates the SD (S) as well as the upper and lower limits of SD for questions WITH logged data (for plotting on the figures)
#i is the question you are using the function on, Q is the resulting dataframe from the function SDSumLog for this question
SDfuncLog <- function(i, Q){ 
  SumAllData2 %>%
    filter(Question == i) %>%
    inner_join(Q, SumAllData2, by = c("Species")) %>%
    mutate(S2 = (n/((n-1) *CL.x)) * wxma) %>%
    mutate(S = (sqrt(S2))) %>% ## previously I was exponentiating here, then calculting the upper and lower limits.  But we need to calculated upSD and dnSD BEFORE exponentiating
    mutate(upSD = exp(WtAveSomeLog + S)) %>%
    mutate(dnSD = exp(WtAveSomeLog - S)) %>%
    mutate_at("WtAveSomeLog", expfunc) #This exponentiates the weighted mean to a normal scale from the log scale
}

#This function calculates the summarized part of S for the questions WITHOUT logged data (Questions 5 and 8)
SDSumNoLog <- function(i){
  AllT %>%
    filter(Question == i & CL.x > 0) %>%
    drop_na(Response) %>%
    group_by(Species) %>%
    mutate(xma = (mResponse - (WtAveSomeLog))^2) %>% 
    mutate(wxma = xma * CL.x) %>% 
    summarise_at(c("wxma", "CL.x"), sum) 
}

#This function calculates S and the upper and lower limits for questions WITHOUT logged data
SDfuncNoLog <- function(i, Q){
  SumAllData2 %>%
    filter(Question == i) %>%
    inner_join(Q, SumAllData2, by = c("Species")) %>%
    mutate(S2 = (n/((n-1) *CL.x)) * wxma) %>%
    mutate(S = (sqrt(S2))) %>% 
    mutate(upSD = (WtAveSomeLog + S)) %>%
    mutate(dnSD = (WtAveSomeLog - S))
}


#### Create the figures -----------------------------------
### If you want to make the figures:
temp5 <- c(3, 4, 5, 6, 7, 8)
AllList <- list()
AllCnt <- list()
for(i in temp5){
  temp6 <- list()
  temp7 <- list()
  temp6 <- AllData %>%
    filter(Question == i) %>%
    drop_na(ResConf)%>%
    filter(CL > 0) %>%
    count(Species, CL, mResponse, name = "N")
  temp8 <- AllData %>%
    filter(Question == i & CL > 0) %>%
    count(Question, Species)
  AllList[[i]] <- temp6
  AllCnt[[i]] <- temp8
}


#Figure when the data is not logged (Questions 5 and 8)
QuantFigNotLog <- function(data1, data2, data3){
  lbls <- setNames(paste(unique(data2$Species), "\nCL:", data2$CL, " N:", data3$n,
                         "Mean:", round(data2$WtAveSomeLog), "\U00B1", round(data2$S), "SD"), unique(data2$Species))
  ggplot() +
    geom_point(data = data1, aes(x = mResponse, y = CL, size = N, fill = N),
               alpha = 0.5, shape = 21, color = "black", stroke = 1.5) +
    geom_vline(data = data2, aes(xintercept = WtAveNoneLog), lty = 2, col = "blue", lwd = 1) +
    geom_rect(data = data2, aes(xmin = dnSD, xmax = upSD, ymin = 0, ymax = 100), color = "lightblue", alpha = 0.25) +
    facet_wrap(~Species,
               labeller = labeller(Species = setNames(unlist(lbls), unique(data1$Species)))) +
    theme_bw() +
    theme(axis.text = element_text(size = 16), axis.title = element_text(size = 18), 
          title = element_text(size = 18), strip.text.x = element_text(size = 16)) +
    ylim(0, 100) +
    scale_size_continuous(range = c(6, 12), breaks = pretty_breaks(4)) +
    scale_fill_viridis(option = "D", breaks = pretty_breaks(4)) +
    guides(fill = guide_legend(), size = guide_legend()) +
    ylab("CLidence Level") +
    xlab("Answer Response") 
}

#Figure when data is logged (Questions 3, 4, 6, and 7)
QuantFigLogScale <- function(data1, data2, data3){
  lbls <- setNames(paste(unique(data2$Species), "\nCL:", data2$CL, " N:", data3$n,
                         "Mean:", round(data2$WtAveSomeLog), "\U00B1", round(data2$S), "SD"), unique(data2$Species))
  ggplot() + 
    geom_point(data = data1, aes(x = mResponse, y = CL, size = N, fill = N), 
               alpha = 0.5, shape = 21, color = "black", stroke = 1.5) +
    geom_vline(data = data2, aes(xintercept = WtAveSomeLog), lty = 2, col = "blue", lwd = 1) +
    geom_rect(data = data2, aes(xmin = dnSD, xmax = upSD, ymin = 0, ymax = 100), color = "lightblue", alpha = 0.25) +
    facet_wrap(~Species, 
               labeller = labeller(Species = setNames(unlist(lbls), unique(data1$Species)))) +
    theme_bw() +
    theme(axis.text = element_text(size = 16), axis.title = element_text(size = 18), 
          title = element_text(size = 18), strip.text.x = element_text(size = 16)) +
    ylim(0, 100) +
    scale_x_log10(breaks = trans_breaks("log10", function(x) 10^x), 
                  labels = trans_format("log10", math_format(10^.x))) +
    scale_size_continuous(range = c(5, 21), breaks = pretty_breaks(4)) +
    scale_fill_viridis(option = "D", breaks = pretty_breaks(4)) +
    guides(fill = guide_legend(), size = guide_legend()) +
    ylab("CLidence Level") +
    xlab("Answer Response (Log Scale)") 
}


#Q3: logged
Q3 <- SDSumLog(3)
Q32 <- SDfuncLog(3, Q3)
AllList[[3]]$Species <- factor(AllList[[3]]$Species, levels = SppList)
AllCnt[[3]]$Species <- factor(AllCnt[[3]]$Species, levels = SppList)
Q32$Species <- factor(Q32$Species, levels = SppList)
QuantFigLogScale(AllList[[3]], Q32, AllCnt[[3]]) + ggtitle("Minimum Spawning Stock Size") #xlim(0, 0.01) + 

#Q4: logged
Q4 <- SDSumLog(4)
Q42 <- SDfuncLog(4, Q4)
AllList[[4]]$Species <- factor(AllList[[4]]$Species, levels = SppList)
AllCnt[[4]]$Species <- factor(AllCnt[[4]]$Species, levels = SppList)
Q42$Species <- factor(Q42$Species, levels = SppList)
QuantFigLogScale(AllList[[4]], Q42, AllCnt[[4]]) + ggtitle("Fecundity (1 adult / N eggs)")
#xlim(0, 0.01) + 

Q42 %>% select(Species, mean = WtAveSomeLog, upSD, dnSD) %>% 
  write_csv('q42.csv')

#Q5: not logged
Q5 <- SDSumNoLog(5)
Q52 <- SDfuncNoLog(5, Q5)
AllList[[5]]$Species <- factor(AllList[[5]]$Species, levels = SppList)
AllCnt[[5]]$Species <- factor(AllCnt[[5]]$Species, levels = SppList)
Q52$Species <- factor(Q52$Species, levels = SppList)
QuantFigNotLog(AllList[[5]], Q52, AllCnt[[5]]) + ggtitle("Proportion of emigrant fish (%)")

#Q6: logged
Q6 <- SDSumLog(6)
Q62 <- SDfuncLog(6, Q6)
AllList[[6]]$Species <- factor(AllList[[6]]$Species, levels = SppList)
AllCnt[[6]]$Species <- factor(AllCnt[[6]]$Species, levels = SppList)
Q62$Species <- factor(Q62$Species, levels = SppList)
QuantFigLogScale(data1 = AllList[[6]], data2 = Q62, 
                 data3 = AllCnt[[6]]) + ggtitle("Mean distance emigrant disperses (km)")
#Q7: logged
Q7 <- SDSumLog(7)
Q72 <- SDfuncLog(7, Q7)
AllList[[7]]$Species <- factor(AllList[[7]]$Species, levels = SppList)
AllCnt[[7]]$Species <- factor(AllCnt[[7]]$Species, levels = SppList)
Q72$Species <- factor(Q72$Species, levels = SppList)
QuantFigLogScale(AllList[[7]], Q72, AllCnt[[7]]) + ggtitle("Max distance emigrant disperses (km)")

#Q8: not logged
Q8 <- SDSumNoLog(8)
Q82 <- SDfuncNoLog(8, Q8)
AllList[[8]]$Species <- factor(AllList[[8]]$Species, levels = SppList)
AllCnt[[8]]$Species <- factor(AllCnt[[8]]$Species, levels = SppList)
Q82$Species <- factor(Q82$Species, levels = SppList)
QuantFigNotLog(AllList[[8]], Q82, AllCnt[[8]]) + ggtitle("Emigrant survival (%)")




```
